<!DOCTYPE html>
<html>

<head>
    <meta charset="utfâ€8">
    <title> Automated Composition Visualization </title>
</head>

<body>

    <h2 align="center">
        Automated Composition Visualization Blog Post
    </h2>

    <p align="center">by Sedona Thomas and Carolyn Wang</p>


    <h3>
        Background
    </h3>
    <p>Writing, visual art, and computer music are all areas of art, which is to say, they are all intensely subjective.
        In this project, we wanted to explore the translations between these artistic mediums by creating a creative
        interpretation of what a "writing style" might look like and sound like, as processed by our mathematical
        understandings and coding decisions, thus putting art forms that are normally separated in conversation with
        each other and giving the user something fun and open-ended to explore.</p>
    <h3>
        Text processing
    </h3>
    <p>Everything the computer produces is based on the initial text input from the user. We then analyze the following
        attributes to determine corresponding characteristics of sound and visuals produced: </p>
    <ul>
        <li><b>Word length:</b> Of course, when someone is speaking, they can choose to speak as slowly or as quickly as
            they
            want to, so there is no fixed length for how long a word might last. To translate that to our computer
            music, we looked at word length as it related to note length. Based on <a
                href="http://norvig.com/mayzner.html">text processing research</a>, the average
            length of a word is 4.79 letters (rounded up to 5 in the code, for convenience; the user will not be
            inputting
            words of length 4.79). In music, we assumed that "the average word" would correspond to "the average note":
            a quarter note played in 4/4 time signature at "moderate tempo," which tops out at a convenient <a
                href="https://www.masterclass.com/articles/music-101-what-is-tempo-how-is-tempo-used-in-music">120
                bpm.</a> From our mathematical calculations, that means the average word (of five letters) would last
            0.5 seconds in sound.</li>
        <li><b>Punctuation:</b> Punctuation is used in speech and in writing often to separate or to create pauses.
            Thus, it makes sense that translating an input with punctuation in it to sound would mean leaving in longer
            gaps between notes where punctuation should be. Based on a subjective ranking of which punctuation marks
            would create the longest pauses (for example, deciding that a dash would create a shorter gap between
            words than a period). </li>
        <li>Letter diversity: </li>
        <li>Word length standard deviation: </li>
        <li>Perplexity: </li>
    </ul>
    <p>Trial and error.</p>
    <p>Choosing sample text options: </p>

    <h3>
        Visualization
    </h3>

    <p></p>

    <h3>
        Automated Composition
    </h3>

    <p>
        Our project uses a Markov model trained on Twinkle Twinkle Little Star to generate a tune derived from the notes
        we generated during the text processing. This Markov chain calculates the probability that a given note will
        be followed by every other note then randomly generates future notes, weighted by their probability.
    </p>

    <h3>
        Future Improvements
    </h3>

    <p>
        In the future, we hope to incorporate a feature for users to input a MIDI file to train the Markov chain, but we
        ran into many browser issues when trying to import the necessary functions. We also hope to add more NLP
        features from built in libraries, but ran into many issues with those as well.
    </p>

    <h3>
        Miscellaneous
    </h3>

    <p></p>

</body>

<script src="main.js"> </script>

</html>